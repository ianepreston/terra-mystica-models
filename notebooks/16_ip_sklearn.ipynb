{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messing around with some functionality to incorporate into the webapp\n",
    "\n",
    "I have a suspicion that scikitlearn will be more performant for actually serving predictions. StatsModels was great for understanding but scikit is more built for production. Let's find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading postgres module without psycopg2 installed. Will crash at runtime if postgres functionality is used.\n",
      "Loading S3 module without the python package boto3. Will crash at runtime if S3 functionality is used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to d6tflow!\n"
     ]
    }
   ],
   "source": [
    "import d6tflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from terra_mystica_models.models.train_model import TaskSkLearnModel, TaskScoreTurnModel\n",
    "from terra_mystica_models.models.analysis import TaskScoreTurnModelInputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Informed scheduler that task   TaskSkLearnModel__99914b932b   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "INFO: Worker Worker(salt=078014271, workers=1, host=terra, username=Ian, pid=6872) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 TaskSkLearnModel()\n",
      "\n",
      "Did not run any tasks\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "INFO: Informed scheduler that task   TaskScoreTurnModelInputs__99914b932b   has status   DONE\n",
      "INFO: Done scheduling tasks\n",
      "INFO: Running Worker with 1 processes\n",
      "INFO: Worker Worker(salt=414272247, workers=1, host=terra, username=Ian, pid=6872) was stopped. Shutting down Keep-Alive thread\n",
      "INFO: \n",
      "===== Luigi Execution Summary =====\n",
      "\n",
      "Scheduled 1 tasks of which:\n",
      "* 1 complete ones were encountered:\n",
      "    - 1 TaskScoreTurnModelInputs()\n",
      "\n",
      "Did not run any tasks\n",
      "This progress looks :) because there were no failed tasks or missing dependencies\n",
      "\n",
      "===== Luigi Execution Summary =====\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run these once to generate pickle files\n",
    "d6tflow.run(TaskSkLearnModel())\n",
    "d6tflow.run(TaskScoreTurnModelInputs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is that I want to generate pickled artifacts of anything I'll need from the trained models. That way I can just copy them into a container or whatever and deploy something without all these training/exploration requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now the way I'm loading it up is a little hacky. I'll have to do something to export the file into the webapp folder with clean names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from terra_mystica_models import practice_app as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk2 = pa.load_model_skl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm2 = pa.load_model_sm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = pa.generate_input_series(\"SCORE2\", \"SCORE3\", \"SCORE4\", \"SCORE5\", \"SCORE6\", \"SCORE7\", [\"BON1\", \"BON2\", \"BON3\", \"BON4\", \"BON5\", \"BON6\", \"BON7\"], \"darklings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.905517578125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk2.predict(test_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.948226348048324"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm2.predict(test_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.1 ms ± 227 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sk2.predict(test_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166 µs ± 3.34 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sm2.predict(test_input)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow, I'm glad I checked. Statsmodels is way faster! That's confusing but nice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pickled sklearn model is way smaller, a few KB vs a few MB, but I'd rather have a bigger image that can generate faster predictions. That's super weird, I'm really surprised statsmodels is so much faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I'm doing this sort of testing, let's see how long it's taking me to generate the input series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42 ms ± 156 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pa.generate_input_series(\"SCORE2\", \"SCORE3\", \"SCORE4\", \"SCORE5\", \"SCORE6\", \"SCORE7\", [\"BON1\", \"BON2\", \"BON3\", \"BON4\", \"BON5\", \"BON6\", \"BON7\"], \"darklings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, if I was using scikit that would be the bottleneck, but using statsmodels this is actually the slower part. That's interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
